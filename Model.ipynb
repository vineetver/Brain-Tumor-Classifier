{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py \n",
    "import cv2 \n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Dataset:\n",
    "\n",
    "This brain tumor dataset containing 3064 T1-weighted contrast-inhanced images\n",
    "from 233 patients with three kinds of brain tumor: meningioma (708 slices),\n",
    "glioma (1426 slices), and pituitary tumor (930 slices). Due to the file size\n",
    "limit of repository, we split the whole dataset into 4 subsets, and achive\n",
    "them in 4 .zip files with each .zip file containing 766 slices.The 5-fold\n",
    "cross-validation indices are also provided.\n",
    "\n",
    "---\n",
    "\n",
    "This data is organized in matlab data format (.mat file). Each file stores a struct\n",
    "containing the following fields for an image:\n",
    "\n",
    "cjdata.label: 1 for meningioma, 2 for glioma, 3 for pituitary tumor\n",
    "cjdata.PID: patient ID\n",
    "cjdata.image: image data\n",
    "cjdata.tumorBorder: a vector storing the coordinates of discrete points on tumor border.\n",
    "For example, [x1, y1, x2, y2,...] in which x1, y1 are planar coordinates on tumor border.\n",
    "It was generated by manually delineating the tumor border. So we can use it to generate\n",
    "binary image of tumor mask.\n",
    "cjdata.tumorMask: a binary image with 1s indicating tumor region\n",
    "\n",
    "---\n",
    "\n",
    "This data was used in the following paper:\n",
    "\n",
    "1. Cheng, Jun, et al. \"Enhanced Performance of Brain Tumor Classification via Tumor Region Augmentation\n",
    "   and Partition.\" PloS one 10.10 (2015).\n",
    "2. Cheng, Jun, et al. \"Retrieval of Brain Tumors by Adaptive Spatial Pooling and Fisher Vector\n",
    "   Representation.\" PloS one 11.6 (2016). Matlab source codes are available on\n",
    "   [github](https://github.com/chengjun583/brainTumorRetrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.mat\n",
      "1000.mat\n",
      "1500.mat\n",
      "2000.mat\n",
      "2500.mat\n",
      "3000.mat\n"
     ]
    }
   ],
   "source": [
    "# Converting all the data into Python list\n",
    "\n",
    "data = []\n",
    "for i in range(1, 3064 + 1):\n",
    "    filename = str(i) + \".mat\"\n",
    "    tumordata = h5py.File(os.path.join('./images/', filename), \"r\")\n",
    "    data.append(tumordata)\n",
    "    if i % 500 == 0:\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting image data from Python List\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "N = len(data)\n",
    "\n",
    "temp = round(4 * N / 5)  # using 4/5th as training data\n",
    "\n",
    "for i in range(temp):\n",
    "    image = data[i][\"cjdata\"][\"image\"][()]\n",
    "\n",
    "    if image.shape == (512, 512):\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        x_train.append(image)\n",
    "\n",
    "        label = int(data[i][\"cjdata\"][\"label\"][()]) - 1\n",
    "        y_train.append(label)\n",
    "\n",
    "# x_test and y_test\n",
    "for i in range(temp, N):\n",
    "    image = np.asarray(data[i][\"cjdata\"][\"image\"][()])\n",
    "\n",
    "    if image.shape == (512, 512):\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        x_test.append(image)\n",
    "\n",
    "        label = int(data[i][\"cjdata\"][\"label\"][()]) - 1\n",
    "        y_test.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train).reshape(-1, 512, 512, 1)\n",
    "x_test = np.array(x_test).reshape(-1, 512, 512, 1)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation using Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image (InputLayer)          [(None, 512, 512, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 246, 246, 64)      31040     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 61, 61, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 61, 61, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 31, 31, 128)       991360    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 15, 15, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 15, 15, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 256)         1605888   \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              4195328   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,088,579\n",
      "Trainable params: 7,087,683\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT = keras.Input(shape=(512, 512, 1), name=\"image\")\n",
    "\n",
    "x1 = Conv2D(64, (22, 22), strides=2)(INPUT)\n",
    "x1 = MaxPooling2D((4, 4))(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "\n",
    "x2 = Conv2D(128, (11, 11), strides=2, padding=\"same\")(x1)\n",
    "x2 = MaxPooling2D((2, 2))(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "\n",
    "x3 = Conv2D(256, (7, 7), strides=2, padding=\"same\")(x2)\n",
    "x3 = MaxPooling2D((2, 2))(x3)\n",
    "x3 = BatchNormalization()(x3)\n",
    "\n",
    "x4 = Flatten()(x3)\n",
    "x4 = Activation(\"relu\")(x4)\n",
    "\n",
    "x5 = Dense(1024, \"relu\")(x4)\n",
    "\n",
    "x6 = Dense(256, \"relu\")(x5)\n",
    "\n",
    "x9 = Dense(3)(x6)\n",
    "pred = Activation(\"softmax\")(x9)\n",
    "\n",
    "model = keras.Model(inputs=INPUT, outputs=pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "77/77 [==============================] - 99s 1s/step - loss: 1.8329 - accuracy: 0.6051 - val_loss: 0.0751 - val_accuracy: 0.9918\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 86s 1s/step - loss: 0.6939 - accuracy: 0.7151 - val_loss: 12.1888 - val_accuracy: 0.0082\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 86s 1s/step - loss: 0.5672 - accuracy: 0.7640 - val_loss: 0.9664 - val_accuracy: 0.8369\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 86s 1s/step - loss: 0.4682 - accuracy: 0.8067 - val_loss: 2.1939 - val_accuracy: 0.6493\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 86s 1s/step - loss: 0.3735 - accuracy: 0.8391 - val_loss: 13.1451 - val_accuracy: 0.0049\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 87s 1s/step - loss: 0.3418 - accuracy: 0.8600 - val_loss: 8.2745 - val_accuracy: 0.1060\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 87s 1s/step - loss: 0.2783 - accuracy: 0.8867 - val_loss: 15.2113 - val_accuracy: 0.1387\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 87s 1s/step - loss: 0.2258 - accuracy: 0.9200 - val_loss: 2.2997 - val_accuracy: 0.9005\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 87s 1s/step - loss: 0.1801 - accuracy: 0.9298 - val_loss: 5.4564 - val_accuracy: 0.8825\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 87s 1s/step - loss: 0.1688 - accuracy: 0.9438 - val_loss: 8.2177 - val_accuracy: 0.8467\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 86s 1s/step - loss: 0.1364 - accuracy: 0.9507 - val_loss: 18.9245 - val_accuracy: 0.5661\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 86s 1s/step - loss: 0.1168 - accuracy: 0.9659 - val_loss: 10.3547 - val_accuracy: 0.5579\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 86s 1s/step - loss: 0.0937 - accuracy: 0.9688 - val_loss: 9.3948 - val_accuracy: 0.7798\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 86s 1s/step - loss: 0.1368 - accuracy: 0.9700 - val_loss: 9.8803 - val_accuracy: 0.6313\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 86s 1s/step - loss: 0.0811 - accuracy: 0.9778 - val_loss: 18.6637 - val_accuracy: 0.4502\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 86s 1s/step - loss: 0.0956 - accuracy: 0.9754 - val_loss: 26.1808 - val_accuracy: 0.6966\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 86s 1s/step - loss: 0.0534 - accuracy: 0.9869 - val_loss: 14.5453 - val_accuracy: 0.2300\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 86s 1s/step - loss: 0.0559 - accuracy: 0.9844 - val_loss: 8.3408 - val_accuracy: 0.5530\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 86s 1s/step - loss: 0.0349 - accuracy: 0.9918 - val_loss: 14.9897 - val_accuracy: 0.7374\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 85s 1s/step - loss: 0.1112 - accuracy: 0.9840 - val_loss: 23.1015 - val_accuracy: 0.1729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22256efee50>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29c75b1f656e0b1ae38298d922e204e268fabb475feb2323015295e781085b10"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
